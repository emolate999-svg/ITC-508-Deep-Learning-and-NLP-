{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnxkiRoumNTd"
      },
      "source": [
        "# ***Installing Dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnA1vejS-lOX",
        "outputId": "51241177-0e56-4a7a-db91-1afd57dcfe30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade transformers datasets evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qPQjxi0SqHj",
        "outputId": "4d63fe1d-1296-4e48-a3b0-82f9be06b72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.10)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install textstat datasets transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so-MCOgBIeTY"
      },
      "source": [
        "# ***Setting up the Environment and Loading Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment handles data loading, preprocessing, and conversion of a news dataset for Transformer-based model fine-tuning. It first imports the necessary libraries—pandas for structured data manipulation, datasets from Hugging Face for model-ready data formatting, and re for regular expression-based text cleaning. The clean_text() function is defined to standardize and sanitize textual data by converting text to lowercase, removing HTML tags, URLs, and excessive whitespace. This ensures that all input text is consistent, noise-free, and suitable for model training. The script then attempts to load the dataset news-article-categories.csv using UTF-8 encoding, a common standard for text-based data such as Kaggle datasets, while handling potential file-loading errors gracefully.\n",
        "\n",
        "Once the dataset is successfully loaded, the script performs systematic preprocessing and dataset preparation. It selects only the relevant columns (body and title), renames them to text and summary for consistency, and removes missing values to maintain data quality. The cleaning function is applied to both columns, producing a uniform and readable dataset. After preprocessing, the cleaned data is converted into a Hugging Face Dataset object, which facilitates efficient tokenization and integration with Transformer models. Finally, the dataset is split into training and testing subsets using an 80–20 ratio, stored in a DatasetDict structure, ensuring an organized and balanced division of data for model fine-tuning and evaluation."
      ],
      "metadata": {
        "id": "X3e9JU1UzRPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seBStuZT66cA",
        "outputId": "7be701dd-2573-4821-80ce-00ac343a4445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded 'news-article-categories.csv'\n",
            "\n",
            "--- Applying preprocessing to the dataset ---\n",
            "Preprocessing complete. Example of cleaned article:\n",
            "in october 2017, carolyn kramer received a disturbing phone call. the former modeling agent listened intently as a model she used to represent told her that a famous french photographer, who still shoots for top publications, raped her when she was 16. shortly after meeting the man at a restaurant in 1983, the model said she blacked out after drinking one glass of champagne, then woke up in his bed the next morning with a sore and bruised vagina. the woman, who preferred to remain anonymous, confirmed this story with huffpost, but did not want to name the photographer for fear of legal repercussions. “he was one of the photographers that agents and clients and young girls basically knew was lecherous,” kramer said, claiming that she and other agents sent their models to him in the ’80s anyway. “[but] what i didn’t realize [at the time] is that he was raping girls.” kramer said she broke down crying after the woman relayed her story of assault. “in that moment i felt that i let down the models who i represented over the course of 20 years,” she said. “it made me feel like, here it is in front of my face now and i didn’t do anything to change [it.]” it’s been 14 years since kramer left the fashion business. but throughout the two decades she spent working as a modeling agent in new york city in the 1980s, ’90s and early 2000s, kramer said she knew about rampant sexual misconduct in her industry ― and didn’t protect her models from the egregious behavior. now, amid the domino-like fall of so many high-profile alleged sexual offenders, the 58-year-old can’t stop thinking about how she and other agents sent girls, some as young as 13, to modeling gigs with photographers who were rumored to be sexual predators. so in october, the former agent decided to speak out. “many of these girls who are assaulted [as models] aren’t older than 15 years old,” she wrote in a facebook post. “and i stand here to say how ashamed i am of myself for not having had the tools or the resources or guts to stop it.” kramer’s peers queued up in the post’s comments section to corroborate her story. one of her former colleagues, ex-model kristen noel, said her agency, elite model management, sent her to paris in the early ’80s to stay with an agent who repeatedly groped and forcibly kissed her. she was 16. “elite protected him and disconnected from their responsibility to me,” noel told huffpost. another commenter, hair and makeup artist dawn jacobson, said she saw agencies regularly endanger models when she worked in milan in the ’80s. according to her, companies sent young women to live in residences ― one of which was reportedly known as “clitoride,” italian for “clitoris” ― where they were preyed on by wealthy italian men. “i think the agencies have massive culpability because they don’t necessarily care about anything other than who gets the booking,” the 59-year-old, who still works in fashion, told huffpost. “it becomes a little bit of a human trafficking kind of thing.” kramer’s post, her first public denouncement of the sexual harassment and abuse she’d witnessed and heard about in the fashion industry, clearly struck a nerve. as the #metoo revolution continues to spark a national dialogue on sexual misconduct, the former agent wants to expose exactly how the very modeling agencies she worked for enabled predators, a disturbing reality that she believes still exists today. kramer, a new jersey native, doesn’t seem like the type to stay silent. she has a self-described “big personality” and speaks bluntly with a slight new york accent. in a recent facebook profile photo, she’s wearing a shirt that reads “fuck trump” and raising her middle finger. but since she retired from the fashion world in 2004, kramer said she felt like nobody ― primarily, the media ― was interested in what she had to say. only recently, the former agent noted, have news outlets begun systematically covering the kinds of abuse allegations she wants to condemn. it’s true that sexual assault accusations made against fashion photographer terry richardson date back to 2001, and that he was only officially dropped by certain top magazines and brands in october 2017. (richardson has long denied any nonconsensual behavior.) and while at least 18 current and former male models recently accused famed photographer bruce weber of sexual harassment (weber has denied these claims), one of whom has filed a lawsuit, industry insiders claim there is a long list of predators who still thrive in a largely unregulated profession that combines young models, big male egos and drugs. kramer’s story dates back to 1983, when she was hired by the industry’s top agency, elite model management, as an assistant booking agent in new york. her previous fashion industry jobs had been horrible. kramer once worked with a photographer who she said cornered her in his office and tried to forcibly kiss her. and she worked for foster-fell model management, which she called a “slimy, horrible” agency. “the models were basically prostitutes,” she said. ”[the owner] would have parties i would be at with licentious business men who were only there to fuck the models.” (jeremy foster-fell, who co-founded the now-defunct agency in 1970, denied these claims to huffpost. “to say there was an arrangement of financial exchange and sexual favors would be completely out of whack,” he said, adding, however, that “if you’re looking after a whole bunch of good-looking ladies who are running around manhattan, you’re going to be running into trouble here and there sometimes.”) but at 24, kramer found herself employed by the modeling world’s gold standard, an agency that represented cindy crawford and linda evangelista, where she didn’t expect to encounter abusive men. her transition to elite was “like going from community college to harvard,” she said. sadly, kramer’s optimism was quickly dashed. at elite new york, her job frequently involved booking models on “go-sees,” the name for appointments during which photographers or designers scout new faces for upcoming shoots. in these meetings, vulnerable young women’s success often depends on impressing (mostly) powerful men. kramer said she and other elite agents would send models, who in many cases were under 16 and had never been to new york city, on appointments with nothing more than subway fare and a map. according to kramer, the girls mostly went alone, because at the time there were no laws requiring guardians to accompany underage models on shoots. new york passed a bill in 2013 that, among other things, requires models under 16 to have chaperones. but before that, a 2012 study by model alliance, an organization that advocates for labor rights in fashion, found that 52 percent of models are rarely or never accompanied by guardians to a shoot, despite the fact that the majority of models start working between age 13 and 16. kramer quickly learned about the perils of go-sees and photo shoots. though the former agent says that the models she represented at the time didn’t tell her directly about being sexually harassed or assaulted by photographers ― likely, she said, because they were terrified of losing job opportunities ― kramer soon heard through industry gossip with colleagues who the predators were. “i wouldn’t have even called it a secret,” she said. “it was just sort of common hearsay that this list of photographers were pigs...i had to make the appointments with [these men]. it would make me gag, but i had to do my job or i’d be fired.” another elite employee, marie anderson boyd, who was an agent and vice president at the company’s chicago office between 1985 and 1990, said models would regularly tell her about the sexual misconduct they experienced on go-sees. ”[some photographers] will think nothing of walking over to some teen girl who’s brand new to the business, taking her top off, unbuttoning her bra and saying something like, ‘i want you to look at me and think of ... giving me oral sex,’” she said. “and a lot of girls have never even done that [before], so they don’t even know what the [photographers] mean.” anderson boyd said she never told her managers at elite about the models’ abusive stories, in part because executives like john casablancas and gerald marie also allegedly engaged in misconduct. “they established a culture of compliance with sexually predatory behavior,” she said. “that trickled down into everything everybody did.” indeed, during kramer’s first year at elite, the agency’s late founder, the then-41-year-old casablancas, was having a public affair with an underage model named stephanie seymour. kramer was horrified that casablancas, with his movie-star good looks and “intoxicating” charisma, was committing statutory rape. “as a young little upstart, i was very in awe of him,” she said. “but at the same time i’m thinking to myself, stephanie’s supposed to be at a vogue shooting at 9 a.m. and she’s still in bed with john. i thought it was wrong and i honestly couldn’t believe it went on. it made me sick.” other alleged abuses at elite unfurled from there. gerald marie, the head of elite paris, was in his 30s when he allegedly raped a 17-year-old model named carré otis on multiple occasions, which she detailed in her 2011 memoir. at the time, otis was temporarily staying with him while she was modeling abroad in the mid-’80s. she didn’t feel as though she could tell the agency about the abuse. “when [elite] new york said goodbye to me and put me in gerald’s apartment, he was like my new owner,” otis told huffpost. “there was no one in new york who created a connection with me and said, ‘hey, here’s the way it should go, and if it doesn’t go this way, here’s a number to call.’ it was just really a hand-off.” “there was a below-the-radar understanding that the [executives] of elite [casablancas and marie] were sleeping with young women,” kramer said. “i’m working at an agency where statutory rape is in front of my face and yet i can’t do anything.” kramer said at 24 she herself was groped by a high-profile agent who went on to become an elite executive. “i was sitting on his lap and his hands were all over me, coming around [my waist] and trying to grab my breast,” she said. “i didn’t react because i was so accustomed to seeing photographers be touchy-feely with models.” kramer did not tell anyone at elite about the misconduct, because she said it never occurred to her that such commonplace behavior was worth reporting, never mind addressing. and those who tried to call out problematic behavior didn’t get very far. in 2000, anderson boyd told new york magazine that she remembered watching two female executives plead with marie and casablancas to stop sleeping with underage women. anderson boyd says marie’s response was, “we are men. we have our needs.” “i was grossed out by what was happening,” the 59-year-old told huffpost. “and that’s why i quit.” ultimately, anderson boyd and kramer agreed that elite never trained agents to speak with models about sexual misconduct. both women say they and other agents they knew did not prepare models for how to deal with predatory behavior. “it was not handled like a traditional corporation where you’re handed a sexual harassment manual,” anderson boyd said. “i did not know how to help [the models’] working conditions.” their account matches the experiences of women at other agencies at the time. for example, when former model lesa amoore was 17, she said her agent at the now-defunct riccardo gay model management company warned her that a photographer she was about to shoot with in milan could “be a little weird.” amoore said that during the subsequent shoot, when she was wearing only a bra and underwear, the photographer unzipped his pants, pulled out his penis and asked whether he could masturbate. according to the former model, now 48, she put on her clothes and ran out of the room. amoore said that when she told her agent about the photographer’s behavior, he responded, “i’m so sorry, that happens sometimes with him.” sara ziff, who began modeling at age 14 in the late ’90s and later founded model alliance, told the new york times last year that she too was regularly asked by photographers to get naked or topless without prior warning and, in at least one instance, was told to sit on her male booker’s lap. “when i first started modeling, i did not feel protected by my agency [next management],” she told huffpost. “in some cases, i felt like they were facilitating meetings [with powerful people] that were not clearly work opportunities ― they felt more like being set up on a date.” though the modeling industry is now more regulated than it was in decades past, abuse is reportedly still frequent. a whopping 87 percent of models say they’ve been asked to get naked without prior warning, while 30 percent have experienced “inappropriate touching” on the job and 28 percent have been pressured to have sex at work, according to model alliance. model cameron russell’s instagram is filled with her own colleagues’ stories of being preyed on at go-sees and shoots. a 22-year-old model wrote about how a male photographer pulled down her bra and started kissing her breasts six months ago. another woman recalled how, as a 14-year-old model, a photographer made her change in front of him, rubbed oil on her legs, and, after asking if she was a virgin, said, “you make me want to go to jail.” the collection of horror stories portrays male photographers masturbating in front of young models, asking for sexual favors, and, in one case, penetrating a 15-year-old with his finger to make the photos “look more sensual.” ziff said that beyond adhering to the 2013 bill, even the best-intentioned agencies still don’t have firm policies in place to protect their models from sexual misconduct. “they tell the girls that if they are in a situation that feels uncomfortable: ‘go to the bathroom and walk out,’ ‘feel free to call me,’ and ‘you don’t have to do anything you don’t want to do,’” the 35-year-old explained. “[they should] take a preventative approach that doesn’t allow those situations to happen in the first place. it’s much easier said than done to walk out of a shoot, especially if you’re young, maybe english isn’t your first language, and you’re working with someone who could make or break your career.” in fact, model alliance found that 70 percent of models surveyed didn’t feel they could report sexual misconduct to their agencies. of those who did, two-thirds said their agents didn’t consider the behavior problematic, and, in a few cases, even encouraged models to sleep with predators to advance their careers. model jason boyce, who filed a lawsuit against bruce weber for sexual misconduct last year, is also suing his agency, soul artist management. according to the court filing, boyce claimed the agency knew about weber’s predatory behavior and alleged that his agent told him to “nail” his shoot with the famous photographer. “the culture was: you did what you were told. that was how they sold it,” he said in an interview with the business of fashion. “if you do what i tell you, you’ll make it. ... my agent told me that all the time.” jilian gotlib, a manager and booking agent who worked for elite in the ’80s and re-joined the company in 2005, spoke to huffpost on behalf of the organization. she disputed kramer’s assertion that agents knowingly sent models to photographers who were rumored to be sexual predators, suggesting that kramer “goes overboard, maybe, with criticizing the industry.” “we would always be careful, check out [the photographer] and tell our models, ‘if [the photographers] ask you to do anything that we didn’t tell you was going to happen, let us know,’” she explained. “some girls would just go ahead anyway, but we would always warn people: ‘call me if anything seems untoward.’ i think we would try not to work with a lot of those photographers if we heard problems.” trudi tapscott, who worked as an agent and director at elite from the early ’80s until the early ’90s, reiterated gotlib’s point, explaining that she told young women about potentially creepy photographers ahead of time. “i’ve had very honest conversations [about] what to do when [photographers] do this and what to do when [photographers] do that,” she told huffpost. however, tapscott added: “at this point i consider [those conversations] complicit. but then i thought i was helping them survive, which sounds so stupid now.” as for alleged in-house predators such as marie, gotlib said, “i knew nothing about anything that might have been going on there.” throughout her career kramer worked at four other agencies ― the now-defunct name management and company management, as well as next management and the marilyn model agency ― where she said she also regularly witnessed young girls being preyed on at dinner parties and clubs. she said agencies organized events at hot spots such as new york’s indochine or the ritz in paris, where models mingled in clouds of cigarette smoke with important editors and photographers who could “make or break careers.” “i saw 14- and 15-year-olds sitting on the laps of these photographers,” she said. “these guys would just have their hands all over these girls.” ultimately, kramer said she didn’t think she could call out the complicit behavior without losing her job. “working for elite [and the other agencies] manipulated me into thinking it was ok,” she said. “i’m not trying to squiggle out of this, by the way. i’m sick to my stomach that i was part of this poison. it sickens me.” representatives for next management and the marilyn model agency did not respond to huffpost’s request for comment. kramer left the industry in 2004 when she was working at the marilyn model agency, saying she was disgusted by how young the models had become. but the former agent said she didn’t process the sexual misconduct ― or her role in enabling it ― until the following year, when she planned to write a book about her career. “i really started becoming more in touch with, ‘holy shit, what did i do? what did i see? what did i feel? what did i know?’” she said. kramer never wrote the book, but since her october facebook post, models have contacted her with more and more stories recalling sexual harassment and assault in the fashion world. even before posting on social media, kramer had started working with ziff at model alliance to publicize industry abuse. the organization recently proposed a program to address sexual misconduct in the fashion, entertainment and media industries that would, among other things, have a third party provide sexual harassment training and implement proper complaint procedures. but kramer says agents still working in the business aren’t embracing her efforts. “a lot of people aren’t talking to me anymore because they know i’m on top of this,” she said. “they are afraid of losing their standing with these photographers and editors.” there are still many “terry richardsons” in the industry, kramer said, men whose predatory behavior the fashion world ignores. “we all knew terry richardson was sexually abusing these girls and yet we still kept sending them on go-sees and to the bookings themselves,” she said. “if you’ve got a $20 million revlon contract weighing in the balance ... yet you know terry is abusing these girls, what do we do? do we say no to terry? no, [we] don’t.” moving forward, kramer believes that if executives at top agencies spoke out about malpractice, they could truly force industrywide change. kramer also thinks agencies need to stop accepting models under 16, but at the very least, she urges them to better protect young women against possible predators. “if i could get the owners to say to themselves, ‘maybe we shouldn’t send 14-year-olds out on go-sees,’ and, ‘maybe we should make sure these photographers that are on the blacklist are never alone with a model,’ i would feel my own shame and guilt for not having done more when i was an agent [slightly dissipate],” she said. “[then] maybe i’d be able to let myself off the hook a little bit.” do you have a story about harassment or discrimination that you’d like to share? email: angelina.chapin@huffpost.com.\n",
            "\n",
            "Dataset structure:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'summary', '__index_level_0__'],\n",
            "        num_rows: 5497\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'summary', '__index_level_0__'],\n",
            "        num_rows: 1375\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "import re # Import the regular expression library\n",
        "\n",
        "# --- (A) CREATE A CLEANING FUNCTION ---\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str): # Handle potential non-string data\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# --- 1. Load Your Custom Dataset ---\n",
        "try:\n",
        "    # Changed encoding to 'utf-8', which is standard for Kaggle datasets\n",
        "    df = pd.read_csv('news-article-categories.csv', encoding='utf-8')\n",
        "    print(\"Successfully loaded 'news-article-categories.csv'\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'news-article-categories.csv' not found.\")\n",
        "    df = None # Set df to None if file not found\n",
        "\n",
        "if df is not None:\n",
        "    # --- 2. Preprocess and Prepare the Dataset ---\n",
        "    # --- THIS IS THE FIX ---\n",
        "    # Select the correct columns from the new dataset ('body' and 'title')\n",
        "    df = df[['body', 'title']]\n",
        "    # Rename them to the standard names the rest of the script expects ('text' and 'summary')\n",
        "    df.columns = ['text', 'summary']\n",
        "\n",
        "    # Handle potential missing values in the new dataset\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # --- (B) APPLY THE CLEANING FUNCTION TO YOUR DATA ---\n",
        "    print(\"\\n--- Applying preprocessing to the dataset ---\")\n",
        "    df['text'] = df['text'].apply(clean_text)\n",
        "    df['summary'] = df['summary'].apply(clean_text)\n",
        "    print(\"Preprocessing complete. Example of cleaned article:\")\n",
        "    print(df.iloc[0]['text'])\n",
        "\n",
        "    # --- 3. Convert to a Hugging Face Dataset ---\n",
        "    hg_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    # --- 4. Split into Training and Validation Sets ---\n",
        "    train_test_split = hg_dataset.train_test_split(test_size=0.2)\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_test_split['train'],\n",
        "        'test': train_test_split['test']\n",
        "    })\n",
        "\n",
        "    print(\"\\nDataset structure:\")\n",
        "    print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLV_fY5IoPO"
      },
      "source": [
        "# ***Tokenization***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code focuses on tokenization and data preparation for fine-tuning the facebook/bart-base model. It begins by importing the AutoTokenizer class from the Hugging Face Transformers library and defining the model checkpoint. The BART model was selected for its strong performance in text summarization and sequence-to-sequence tasks. The tokenizer corresponding to this checkpoint is loaded using AutoTokenizer.from_pretrained(model_checkpoint), ensuring that the tokenization process aligns with the model’s pre-training configuration. This step converts raw text into a sequence of numerical tokens that the model can understand while maintaining vocabulary consistency with BART’s architecture.\n",
        "\n",
        "A custom preprocessing function, preprocess_function(), is then defined to tokenize both the input articles and their corresponding summaries. The input text is truncated to a maximum length of 1024 tokens, while summaries are limited to 128 tokens to maintain concise outputs. A filter is also applied to exclude articles longer than 500 words, reducing computational overhead and preventing token overflow during training. The map() method applies the tokenization across the dataset in batches, resulting in a structured dataset containing tokenized inputs and labels ready for model fine-tuning. This systematic preprocessing ensures the data is optimized for the BART model’s encoder-decoder framework, facilitating efficient and context-aware headline generation."
      ],
      "metadata": {
        "id": "MuVixAyFzTyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "b13e2bfa3d624cc498bd2d8c300ff642",
            "91f2f292ed8347d8bd15ce1bca5a2ffa",
            "94137c4a0a25440c9c95e027e43760b4",
            "7bfa75101ed34b669c61f4537bf8e19c",
            "12b22da8f1f64d2982594d5a85f14926",
            "ac65e29d57af4b8085b27d2e7aecdba8",
            "32c34aa74fdb460da8ef023424e74687",
            "9084a52f55ed4ff4b63bc9c257de1806",
            "a200d03fda424f45869fd0ebcfa103b5",
            "c8e07f49906b4a09af67b1631ce7abc1",
            "d0dff8f712934fa7970cde3dad3c8a77",
            "e397574e8bd149f6bc46583b7ae0f42b",
            "498c80767dbe4a65a5627826defa52bb",
            "08d199b1acdb422abd16106adeb969c2",
            "d312e3bfa43d47ada098a2ea49e6fb54",
            "734297a7e26d4797baca06a2850b625b",
            "e6c9f83e0999494ca8ef3572ed7ebe03",
            "e80ac48f55cc46bcb436a4f8157b0f8c",
            "5717ad74dc8c4f778aecd357bdbdb4e1",
            "2cbc48c8e63f42d6bfebcaf97b2bdc61",
            "1d5ab3db47254c6cb8db282c7e18989c",
            "8865670bc81b487dac831a3f6c4926d0",
            "70834a49b8fb49a2a7d823fddd0fd48c",
            "dabce246638b4be9a6de5faf6544b467",
            "a1fa520c39ef481db10aca6b8d23344e",
            "a6273132062f4f54aaa20be847c9b576",
            "cc36413f96e8485e88b928874fa0d6c1",
            "b5a6071a13414040836600b606a0839b",
            "8200259801d94befbc47944ad58b8890",
            "358a7620c7c04202be048363abe7062b",
            "a74edb05b79a46b5a405de769488386a",
            "601c4340aa564b399705793aa26580cb",
            "dec2636300e744cf83704ebd0dcf25d2",
            "3da7e6b3dc2a41d6be11342d87d90006",
            "42c05f095e674554aec38077b1cd1645",
            "2616897baeb140e0907613d53ec752c6",
            "80c41c2a9ed5447ea2d069a90da5c783",
            "63e3750b4dd34baab57b1c4bd987f8b5",
            "3fd9e6ff668e4926baf065c911b1af42",
            "c29403752b2945d8950b4ecbe6b6437f",
            "7aa2a0f336bc475c91b3e0db36ba29b8",
            "9684c048f8104f98bcfd332c8f8a773d",
            "90cc5df54a2c4b3e8f749796a6a0c281",
            "5c3250f69e52412b8d8b50cb97f92432"
          ]
        },
        "id": "ExZLogj_68YH",
        "outputId": "4d0f2afc-1706-4332-a83c-57b5f17c8cf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13e2bfa3d624cc498bd2d8c300ff642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/5497 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e397574e8bd149f6bc46583b7ae0f42b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/1375 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70834a49b8fb49a2a7d823fddd0fd48c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2817 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3da7e6b3dc2a41d6be11342d87d90006",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/710 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample of tokenized data prepared for T5:\n",
            "dict_keys(['text', 'summary', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# --- 4. Define the Model Checkpoint ---\n",
        "# ## <-- KEY CHANGE: Switched to the smaller t5-small model ---\n",
        "model_checkpoint = \"google-t5/t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# --- 5. Create a T5-Specific Preprocessing Function ---\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # ## <-- KEY CHANGE: Add the prefix to all input articles ---\n",
        "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
        "\n",
        "    # Tokenize the prefixed inputs\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
        "\n",
        "    # Tokenize the target summaries (labels)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"summary\"], max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# --- 6. Apply the Tokenization ---\n",
        "dataset = dataset.filter(lambda x: len(x[\"text\"].split()) < 500)\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "print(\"\\nSample of tokenized data prepared for T5:\")\n",
        "print(tokenized_datasets['train'][0].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haNU_m_nmHaV"
      },
      "source": [
        "# ***Model Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI1KYzyiIsXv"
      },
      "source": [
        "## ***Fine-Tuning the Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section presents the fine-tuning process of the Google T5-small model for automatic news headline generation. After importing the required modules from the Hugging Face Transformers library, nine adjustable hyperparameters—including learning rate, batch sizes, number of epochs, weight decay, warmup steps, and gradient accumulation—are defined to optimize the model’s learning dynamics. The model checkpoint \"google-t5/t5-small\" is loaded using AutoModelForSeq2SeqLM.from_pretrained(), providing a lightweight yet efficient encoder-decoder framework suitable for text summarization tasks. A compute_metrics() function is implemented to evaluate intrinsic text quality through two key measures: average readability using the Flesch Reading Ease Score from TextStat, and average length of generated summaries. These intrinsic metrics complement standard performance measures by ensuring that the outputs are both linguistically fluent and contextually concise.\n",
        "\n",
        "The training configuration is defined using Seq2SeqTrainingArguments, aligning closely with the previous BART model setup to maintain consistency across experiments. This configuration specifies essential parameters such as logging frequency, save strategy, gradient accumulation, and evaluation mode. The Seq2SeqTrainer integrates the model, datasets, tokenizer, and data collator into a unified framework for supervised fine-tuning. The fine-tuning process iteratively updates the model’s weights based on the training data, enhancing its ability to produce coherent, concise, and relevant summaries. After training, the fine-tuned model is saved to a local directory for subsequent evaluation and comparison with the BART model. This process allows a systematic performance analysis between architectures, highlighting the trade-offs between model complexity, readability, and summarization quality."
      ],
      "metadata": {
        "id": "KbBNLSAWzWiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "rYTdNx2d7D0S",
        "outputId": "47b059a3-5e1c-4cad-bfa9-931f5db814e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers library version: 4.57.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2618495268.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting model fine-tuning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 72/354 58:06 < 3:54:06, 0.02 it/s, Epoch 0.40/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.800200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import numpy as np\n",
        "import textstat  # for readability metrics (pip install textstat)\n",
        "\n",
        "print(\"Transformers library version:\", transformers.__version__)\n",
        "\n",
        "# --- 9 ADJUSTABLE HYPERPARAMETERS (Copied from Facebook Config) ---\n",
        "learning_rate = 1e-6                         # 1. Learning rate\n",
        "train_batch_size = 8                         # 2. Training batch size\n",
        "eval_batch_size = 8                          # 3. Evaluation batch size\n",
        "num_train_epochs = 2                         # 4. Number of epochs\n",
        "weight_decay = 0.15                         # 5. Weight decay\n",
        "warmup_steps = 500                           # 6. Warmup steps\n",
        "logging_steps = 50                           # 7. Logging frequency\n",
        "generation_max_length = 128                  # 8. Max length for generated text\n",
        "gradient_accumulation_steps = 2              # 9. Gradient accumulation steps\n",
        "\n",
        "# --- Model Checkpoint ---\n",
        "model_checkpoint = \"google-t5/t5-small\"\n",
        "\n",
        "# --- Compute Metrics (Intrinsic, same as before) ---\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Compute readability metrics (intrinsic quality)\n",
        "    readability_scores = [textstat.flesch_reading_ease(pred) for pred in decoded_preds if pred]\n",
        "    avg_readability = np.mean(readability_scores) if readability_scores else 0\n",
        "\n",
        "    # Compute average length\n",
        "    prediction_lens = [len(pred.split()) for pred in decoded_preds if pred]\n",
        "    avg_length = np.mean(prediction_lens) if prediction_lens else 0\n",
        "\n",
        "    return {\n",
        "        \"avg_readability\": round(avg_readability, 2),\n",
        "        \"avg_length\": round(avg_length, 2),\n",
        "    }\n",
        "\n",
        "# --- Load Pre-trained Model ---\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# --- Prepare Data Collator ---\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# --- Define Training Arguments (Synced with Facebook Version) ---\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./t5_small_finetuned_intrinsic\",  # updated path\n",
        "    do_eval=True,\n",
        "    logging_strategy=\"steps\",                     # ✅ changed to match Facebook setup\n",
        "    logging_steps=logging_steps,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=eval_batch_size,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_steps=warmup_steps,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=generation_max_length,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# --- Initialize Trainer ---\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- Start Fine-Tuning ---\n",
        "print(\"\\nStarting model fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "# --- Save the Fine-Tuned Model ---\n",
        "model_save_path = \"./my_finetuned_t_summarizer_no_ref\"\n",
        "trainer.save_model(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkANW5rcl-yw"
      },
      "source": [
        "## ***Metric of the Fine-Tuned***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section details the evaluation phase of the fine-tuned google-t5/t5-small model using the Hugging Face Transformers and Evaluate libraries. The script begins by loading the saved fine-tuned model from the specified directory and preparing the data collator for consistent batch formatting during evaluation. The ROUGE metric, imported through the evaluate library, serves as the primary quantitative measure for summarization performance, assessing word- and phrase-level similarity between generated and reference summaries. The custom safe_decode() function ensures stability by clipping invalid token IDs and decoding model outputs into readable text without including special tokens. This decoding process is critical for obtaining accurate ROUGE scores and text-based readability assessments.\n",
        "\n",
        "The compute_metrics() function calculates both ROUGE-based and intrinsic quality metrics. ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-Lsum capture the model’s lexical precision, phrase consistency, and structural coherence. Meanwhile, readability is evaluated through the Flesch Reading Ease score, and average summary length is computed to assess linguistic fluency and conciseness. The Seq2SeqTrainer and Seq2SeqTrainingArguments handle the evaluation workflow, enabling automated metric computation with predict_with_generate=True, which generates summaries dynamically for testing. The final printed metrics provide a holistic assessment of the fine-tuned T5 model’s summarization performance, balancing quantitative accuracy and qualitative readability, and facilitating direct comparison with the BART model’s results to identify architectural and optimization differences."
      ],
      "metadata": {
        "id": "UYQE0TGBzZOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPvwLSy9fAA8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import textstat\n",
        "import evaluate  # ✅ use this instead of datasets.load_metric\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "# --- (1) Load Model ---\n",
        "model_path = \"./my_finetuned_t_summarizer_no_ref\"\n",
        "print(f\"Loading fine-tuned model from: {model_path}\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_path)  # Uncomment if needed\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# --- (2) Load ROUGE Metric ---\n",
        "rouge = evaluate.load(\"rouge\")  # ✅ updated import\n",
        "\n",
        "# --- (3) Safe Decode ---\n",
        "def safe_decode(predictions):\n",
        "    decoded = []\n",
        "    for pred in predictions:\n",
        "        pred = np.clip(pred, 0, tokenizer.vocab_size - 1)  # ✅ ensure valid IDs\n",
        "        text = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "        decoded.append(text)\n",
        "    return decoded\n",
        "\n",
        "# --- (4) Compute Metrics ---\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    if predictions.ndim > 2:\n",
        "        predictions = predictions[:, 0, :]  # handle nested arrays\n",
        "\n",
        "    decoded_preds = safe_decode(predictions)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
        "\n",
        "    # --- ROUGE scores ---\n",
        "    rouge_scores = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "    rouge1 = rouge_scores[\"rouge1\"] * 100\n",
        "    rouge2 = rouge_scores[\"rouge2\"] * 100\n",
        "    rougeL = rouge_scores[\"rougeL\"] * 100\n",
        "    rougeLsum = rouge_scores[\"rougeLsum\"] * 100\n",
        "\n",
        "    # --- Readability ---\n",
        "    readability_scores = [textstat.flesch_reading_ease(pred) for pred in decoded_preds]\n",
        "    avg_readability = np.mean(readability_scores)\n",
        "\n",
        "    # --- Average Length ---\n",
        "    prediction_lens = [len(pred.split()) for pred in decoded_preds]\n",
        "    avg_length = np.mean(prediction_lens)\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": round(rouge1, 4),\n",
        "        \"rouge2\": round(rouge2, 4),\n",
        "        \"rougeL\": round(rougeL, 4),\n",
        "        \"rougeLsum\": round(rougeLsum, 4),\n",
        "        \"avg_readability\": round(avg_readability, 2),\n",
        "        \"avg_length\": round(avg_length, 2),\n",
        "    }\n",
        "\n",
        "# --- (5) Evaluation Args ---\n",
        "eval_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./eval_results\",\n",
        "    per_device_eval_batch_size=4,\n",
        "    predict_with_generate=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# --- (6) Trainer ---\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=eval_args,\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- (7) Evaluate ---\n",
        "print(\"\\n🔎 Evaluating fine-tuned model...\")\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "print(\"\\n✅ Evaluation Results:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"• {k}: {v:.4f}\" if isinstance(v, (int, float)) else f\"• {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MuGHspBl2_J"
      },
      "source": [
        "# ***Using the Models***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3f0LhdgIxTz"
      },
      "source": [
        "## ***Using the Fine-Tuned Model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfOLBeTHeM0d",
        "outputId": "fa49c1c6-64a3-4252-bcb0-05809db5559c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.10)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install textstat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section illustrates the interactive inference process for the fine-tuned google-t5/t5-small model, designed for automatic news headline generation. The fine-tuned model and tokenizer are loaded through the Hugging Face pipeline API for the summarization task, which streamlines the end-to-end process from text input to summary generation. The model is retrieved from the saved directory and operated within an interactive loop, allowing users to input news articles and receive real-time summaries. To align with the T5 model’s architecture, each input text is prefixed with the keyword “summarize:”, which helps the model recognize the summarization objective. The script tracks execution time to compute generation speed and efficiency metrics, ensuring the model’s responsiveness in an applied setting.\n",
        "\n",
        "After generating summaries, the system evaluates both quantitative performance and linguistic quality using several metrics. These include generation time, tokens per second, compression ratio, and redundancy ratio, which assess summarization efficiency and lexical diversity. Additionally, sentence-level structural properties—such as average sentence length—and readability indices including Flesch Reading Ease, Gunning Fog Index, SMOG Index, and Automated Readability Index (ARI)—are computed via the TextStat library to measure fluency and accessibility. Together, these metrics provide a holistic understanding of the model’s ability to generate clear, coherent, and concise summaries. This interactive implementation validates the fine-tuned T5 model’s readiness for real-world applications in AI-assisted journalism and content automation systems."
      ],
      "metadata": {
        "id": "CtWUumbGzve4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaQPkSKa8OYu",
        "outputId": "b38862bb-93c0-4aa9-cae4-2570a4e4a8d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Fine-Tuned Summarization Model Loaded\n",
            "Loaded from: ./my_finetuned_t_summarizer_no_ref\n",
            "\n",
            "Enter an article to summarize (or 'quit' to exit): In October 2017, Carolyn Kramer received a disturbing phone call. The former modeling agent listened intently as a model she used to represent told her that a famous French photographer, who still shoots for top publications, raped her when she was 16. Shortly after meeting the man at a restaurant in 1983, the model said she blacked out after drinking one glass of champagne, then woke up in his bed the next morning with a sore and bruised vagina. The woman, who preferred to remain anonymous, confirmed this story with HuffPost, but did not want to name the photographer for fear of legal repercussions. â€œHe was one of the photographers that agents and clients and young girls basically knew was lecherous,â€ Kramer said,Â claiming that she and other agents sent their models to him in the â€™80s anyway. â€œ[But] what I didnâ€™t realize [at the time] is that he was raping girls.â€Â  Kramer said she broke down crying after the woman relayed her story of assault. â€œIn that moment I felt that I let down the models who I represented over the course of 20 years,â€ she said. â€œIt made me feel like, here it is in front of my face now and I didnâ€™t do anything to change [it.]â€ Itâ€™s been 14 years since Kramer left the fashion business. But throughout the two decades she spent working as a modeling agent in New York City in the 1980s, â€™90s and early 2000s, Kramer said she knew about rampant sexual misconduct in her industry â€•Â and didnâ€™t protect her models from the egregious behavior. Now, amidÂ the domino-like fall of soÂ manyÂ high-profileÂ alleged sexual offenders, the 58-year-oldÂ canâ€™t stop thinking about how she and other agents sent girls, some as young as 13,Â to modeling gigs with photographers who were rumored to be sexual predators. So in October, the former agent decided to speak out.Â  â€œMany of these girls who are assaulted [as models] arenâ€™t older than 15 years old,â€Â she wrote in a Facebook post. â€œAnd I stand here to say how ashamed I am of myself for not having had the tools or the resources or guts to stop it.â€ Kramerâ€™s peers queued up in the postâ€™s comments section to corroborate her story.Â One of her former colleagues, ex-model Kristen Noel, said her agency, Elite Model Management, sent her to Paris in the early â€™80s to stay with an agent who repeatedly groped and forcibly kissed her. She was 16. â€œElite protected him and disconnected from their responsibility to me,â€ Noel told HuffPost.Â  Another commenter, hair and makeup artist Dawn Jacobson, said she saw agencies regularly endanger models when she worked in Milan in the â€™80s. According to her, companies sent young women to live in residences â€• one of which was reportedly known as â€œClitoride,â€ Italian for â€œclitorisâ€ â€•Â where they were preyed on by wealthy Italian men. â€œI think the agencies have massive culpability because they donâ€™t necessarily care about anything other than who gets the booking,â€ the 59-year-old, who still works in fashion, told HuffPost. â€œIt becomes a little bit of a human trafficking kind of thing.â€ Kramerâ€™s post,Â her first public denouncement of the sexual harassment and abuse sheâ€™d witnessed and heard about in the fashion industry, clearly struck a nerve.Â As the #MeToo revolution continues to spark a national dialogue on sexual misconduct, the former agent wants to expose exactly how the very modeling agencies she worked for enabled predators, a disturbing reality that she believes still exists today.Â  Kramer, a New Jersey native, doesnâ€™t seem like the type to stay silent. She has a self-described â€œbig personalityâ€ and speaks bluntly with a slight New York accent.Â In a recent Facebook profile photo, sheâ€™s wearing a shirt that reads â€œFuck Trumpâ€ and raising her middle finger. But since she retired from the fashion world in 2004, Kramer said she felt like nobody â€• primarily, the media â€•Â was interested in what she had to say.Â  Only recently, the former agent noted, have news outlets begun systematically covering the kinds of abuse allegations she wants to condemn.Â Itâ€™s true that sexual assault accusations made against fashion photographer Terry Richardson date back to 2001,Â and that he was only officially dropped by certain top magazines and brandsÂ in October 2017.Â (Richardson has long denied any nonconsensual behavior.) And while at least 18 current and former male modelsÂ recently accused famed photographer Bruce Weber of sexual harassment (Weber has denied these claims), one of whom has filed a lawsuit, industry insiders claim there is a long list of predators who still thrive in a largely unregulated profession that combines young models, big male egos and drugs.Â  Kramerâ€™s story dates back to 1983, when she was hired by the industryâ€™s top agency, Elite Model Management, as an assistant booking agent in New York. HerÂ previous fashion industry jobs had been horrible. Kramer once worked with a photographer who she said cornered her in his office and tried to forcibly kiss her. And she worked forÂ Foster-Fell Model Management,Â which she called a â€œslimy, horribleâ€ agency.  â€œThe models were basically prostitutes,â€ she said. â€[The owner] would have parties I would be at with licentious business men who were only there to fuck the models.â€ (Jeremy Foster-Fell, who co-founded the now-defunct agency in 1970,Â denied these claims to HuffPost. â€œTo say there was an arrangement of financial exchange and sexual favors would be completely out of whack,â€ he said, adding, however, that â€œif youâ€™re looking after a whole bunch of good-looking ladies who are running around Manhattan, youâ€™re going to be running into trouble here and there sometimes.â€)Â  But at 24, Kramer found herself employed by the modeling worldâ€™s gold standard,Â an agency that represented Cindy Crawford and Linda Evangelista,Â where she didnâ€™t expect to encounter abusive men. Her transition to Elite was â€œlike going from community college to Harvard,â€ she said. Sadly,Â Kramerâ€™s optimism was quickly dashed.  At Elite New York,Â her job frequently involved booking models on â€œgo-sees,â€ the name for appointments during which photographers or designers scout new faces for upcoming shoots. In these meetings, vulnerable young womenâ€™s success often depends on impressing (mostly) powerful men. Kramer said she and other Elite agents would send models, who in many cases were under 16 and had never been to New York City, on appointments with nothing more than subway fare and a map. According to Kramer, the girls mostly went alone, because at the time there were no laws requiring guardians to accompany underage models on shoots. New York passed a bill in 2013 that, among other things, requires models under 16 to have chaperones. But before that, a 2012 study by Model Alliance, an organization that advocates for labor rights in fashion, found that 52 percent of models are rarely or never accompanied by guardians to a shoot, despite the fact that the majority of models start working between age 13 and 16. Kramer quickly learned about the perils of go-sees and photo shoots.Â Though the former agent says that the models she represented at the time didnâ€™t tell her directly about being sexually harassed or assaulted by photographersÂ â€• likely, she said, because they were terrified of losing job opportunities â€• Kramer soon heard through industry gossip with colleagues who the predators were. â€œI wouldnâ€™t have even called it a secret,â€ she said. â€œIt was just sort of common hearsay that this list of photographers were pigs...I had to make the appointments with [these men]. It would make me gag, but I had to do my job or Iâ€™d be fired.â€Â  Another Elite employee,Â Marie Anderson Boyd, who was an agent and vice president at the companyâ€™s Chicago office between 1985 and 1990, said models would regularly tell her about the sexual misconduct they experienced on go-sees. â€[Some photographers] will think nothing of walking over to some teen girl whoâ€™s brand new to the business, taking her top off, unbuttoning her bra and saying something like, â€˜I want you to look at me and think of ... giving me oral sex,â€™â€ she said. â€œAnd a lot of girls have never even done that [before], so they donâ€™t even know what the [photographers] mean.â€  Anderson Boyd said she never told her managers at Elite about the modelsâ€™ abusive stories, in part because executives like John Casablancas and Gerald Marie also allegedly engaged in misconduct. â€œThey established a culture of compliance with sexually predatory behavior,â€ she said. â€œThat trickled down into everything everybody did.â€Â  Indeed, during Kramerâ€™s first year at Elite,Â the agencyâ€™s late founder, the then-41-year-old Casablancas, was having a public affair with an underage model named Stephanie Seymour. Kramer was horrified that Casablancas, with his movie-star good looks and â€œintoxicatingâ€ charisma, was committing statutory rape.  â€œAs a young little upstart, I was very in awe of him,â€ she said. â€œBut at the same time Iâ€™m thinking to myself, Stephanieâ€™s supposed to be at a Vogue shooting at 9 a.m. and sheâ€™s still in bed with John. I thought it was wrong and I honestly couldnâ€™t believe it went on. It made me sick.â€ Other alleged abuses at Elite unfurled from there. Gerald Marie, the head of Elite Paris, was in his 30s when heÂ allegedly raped a 17-year-old model named CarrÃ© Otis on multiple occasions, which she detailed in her 2011 memoir. At the time, Otis was temporarily staying with him while she was modeling abroad in the mid-â€™80s. She didnâ€™t feel as though she could tell the agency about the abuse.  â€œWhen [Elite] New York said goodbye to me and put me in Geraldâ€™s apartment, he was like my new owner,â€ Otis told HuffPost. â€œThere was no one in New York who created a connection with me and said, â€˜Hey, hereâ€™s the way it should go, and if it doesnâ€™t go this way, hereâ€™s a number to call.â€™ It was just really a hand-off.â€ â€œThere was a below-the-radar understanding that theÂ [executives] of Elite [Casablancas and Marie] were sleeping with young women,â€ Kramer said. â€œIâ€™m working at an agency where statutory rape is in front of my face and yet I canâ€™t do anything.â€ Kramer said at 24 she herself was groped by a high-profile agent who went on to become an Elite executive. â€œI was sitting on his lap and his hands were all over me, coming around [my waist] and trying to grab my breast,â€ she said. â€œI didnâ€™t react because I was so accustomed to seeing photographers be touchy-feely with models.â€ Kramer did not tell anyone at Elite about the misconduct, because she said it never occurred to her that such commonplace behavior was worth reporting, never mind addressing. And those who tried to call out problematic behavior didnâ€™t get very far.Â In 2000, Anderson Boyd told New York Magazine that she remembered watchingÂ two female executives plead with Marie and Casablancas to stop sleeping with underage women.Â Anderson Boyd says Marieâ€™s response was, â€œWe are men. We have our needs.â€ â€œI was grossed out by what was happening,â€ the 59-year-old told HuffPost. â€œAnd thatâ€™s why I quit.â€ Ultimately, Anderson Boyd and Kramer agreed that Elite never trained agents to speak with models about sexual misconduct. Both women say they and other agents they knew did not prepare models for how to deal with predatory behavior.Â Â  â€œIt was not handled like a traditional corporation where youâ€™re handed a sexual harassment manual,â€ Anderson Boyd said. â€œI did not know how to help [the modelsâ€™] working conditions.â€ Their account matches the experiences of women at other agencies at the time. For example, when former model Lesa Amoore was 17, she said her agent at the now-defunct Riccardo Gay Model Management company warned her that a photographer she was about to shoot with in Milan could â€œbe a little weird.â€ Amoore said that during the subsequent shoot, when she was wearing only a bra and underwear, the photographer unzipped his pants, pulled out his penis and asked whether he could masturbate. According to the former model, now 48, she put on her clothes and ran out of the room. Amoore said that when she told her agent about the photographerâ€™s behavior, he responded,Â â€œIâ€™m so sorry, that happens sometimes with him.â€ Sara Ziff, who began modeling at age 14 in the late â€™90s and later founded Model Alliance,Â told The New York TimesÂ last year that she too was regularly asked by photographers to get naked or topless without prior warning and, in at least one instance, was told to sit on her male bookerâ€™s lap.Â  â€œWhen I first started modeling, I did not feel protected by my agency [Next Management],â€ she told HuffPost. â€œIn some cases, I felt like they were facilitating meetings [with powerful people] that were not clearly work opportunities â€• they felt more like being set up on a date.â€ Though the modeling industry is nowÂ more regulatedÂ than it was in decades past, abuse is reportedly still frequent.Â A whopping 87 percent of models say theyâ€™ve been asked to get naked without prior warning, while 30 percent have experienced â€œinappropriate touchingâ€ on the job and 28 percent have been pressured to have sex at work, according toÂ Model Alliance. ModelÂ Cameron Russellâ€™sÂ InstagramÂ is filled with her own colleaguesâ€™ stories of being preyed on at go-sees and shoots. A 22-year-old modelÂ wrote aboutÂ how a male photographer pulled down her bra and started kissing her breasts six months ago. Another womanÂ recalledÂ how, as a 14-year-old model, a photographer made her change in front of him, rubbed oil on her legs, and, after asking if she was a virgin, said, â€œYou make me want to go to jail.â€ The collection of horror stories portrays male photographersÂ masturbatingÂ in front of young models, asking for sexual favors, and, in one case,Â penetratingÂ a 15-year-old with his finger to make the photos â€œlook more sensual.â€ Ziff said that beyond adhering to the 2013 bill, even the best-intentioned agencies still donâ€™t have firm policies in place to protect their models from sexual misconduct. â€œThey tell the girls that if they are in a situation that feels uncomfortable: â€˜Go to the bathroom and walk out,â€™ â€˜Feel free to call me,â€™ and â€˜You donâ€™t have to do anything you donâ€™t want to do,â€™â€ the 35-year-old explained. â€œ[They should] take a preventative approach that doesnâ€™t allow those situations to happen in the first place. Itâ€™s much easier said than done to walk out of a shoot, especially if youâ€™re young, maybe English isnâ€™t your first language, and youâ€™re working with someone who could make or break your career.â€Â  In fact,Â Model AllianceÂ found that 70 percent of models surveyed didnâ€™t feel they could report sexual misconduct to their agencies. Of those who did,Â two-thirds saidÂ their agents didnâ€™t consider the behavior problematic, and, in a few cases, even encouraged models to sleep with predators to advance their careers.Â  Model Jason Boyce, who filed a lawsuit against Bruce Weber for sexual misconduct last year, is also suing his agency, Soul Artist Management. According to the court filing, Boyce claimed the agency knew about Weberâ€™s predatory behavior and alleged that his agent told him to â€œnailâ€ his shoot with the famous photographer. â€œThe culture was: You did what you were told. That was how they sold it,â€ he said in an interview withÂ The Business of Fashion. â€œIf you do what I tell you, youâ€™ll make it. ... My agent told me that all the time.â€ Jilian Gotlib, a manager and booking agent who worked for Elite in the â€™80s and re-joined the company in 2005, spoke to HuffPost on behalf of the organization. She disputed Kramerâ€™s assertion that agents knowingly sent models to photographers who were rumored to be sexual predators, suggesting that KramerÂ â€œgoes overboard, maybe, with criticizing the industry.â€ â€œWe would always be careful, check out [the photographer] and tell our models, â€˜If [the photographers] ask you to do anything that we didnâ€™t tell you was going to happen, let us know,â€™â€ she explained. â€œSome girls would just go ahead anyway, but we would always warn people: â€˜Call me if anything seems untoward.â€™Â I think we would try not to work with a lot of those photographers if we heard problems.â€ Trudi Tapscott, who worked as an agent and director at Elite from the early â€™80s until the early â€™90s,Â reiterated Gotlibâ€™s point, explaining that she told young women about potentially creepy photographers ahead of time.Â â€œIâ€™ve had very honest conversations [about] what to do when [photographers] do this and what to do when [photographers] do that,â€ she told HuffPost. However, Tapscott added: â€œAt this point I consider [those conversations] complicit. But then I thought I was helping them survive, which sounds so stupid now.â€ As for alleged in-house predators such as Marie, Gotlib said, â€œI knew nothing about anything that might have been going on there.â€Â  Throughout her career Kramer worked at four other agencies â€• the now-defunct Name Management and Company Management, as well as Next Management and the Marilyn Model Agency â€• where she said she also regularly witnessed young girls being preyed on at dinner parties and clubs. She said agencies organized events at hot spots such as New Yorkâ€™s Indochine or the Ritz in Paris, where models mingled in clouds of cigarette smoke with important editors and photographers who could â€œmake or break careers.â€ â€œI saw 14- and 15-year-olds sitting on the laps of these photographers,â€ she said. â€œThese guys would just have their hands all over these girls.â€ Ultimately, Kramer said she didnâ€™t think she could call out the complicit behavior without losing her job.Â â€œWorking for Elite [and the other agencies] manipulated me into thinking it was OK,â€ she said. â€œIâ€™m not trying to squiggle out of this, by the way. Iâ€™m sick to my stomach that I was part of this poison. It sickens me.â€Â  Representatives for Next Management and the Marilyn Model Agency did not respond to HuffPostâ€™s request for comment. Kramer left the industry in 2004 when she was working at the Marilyn Model Agency, saying she was disgusted by how young the models had become. But the former agent said she didnâ€™t process the sexual misconduct â€• or her role in enabling it â€• until the following year, when she planned toÂ write a book about her career. â€œI really started becoming more in touch with, â€˜Holy shit, what did I do? What did I see? What did I feel? What did I know?â€™â€ she said. Kramer never wrote the book, but since her October Facebook post, models have contacted her with more and more stories recalling sexual harassment and assault in the fashion world. Even before posting on social media, Kramer had started working with Ziff at Model Alliance to publicize industry abuse. The organization recently proposedÂ a program to address sexual misconduct in the fashion, entertainment and media industries that would, among other things, have a third party provide sexual harassment training and implement proper complaint procedures. But Kramer says agents still working in the business arenâ€™t embracing her efforts. â€œA lot of people arenâ€™t talking to me anymore because they know Iâ€™m on top of this,â€ she said. â€œThey are afraid of losing their standing with these photographers and editors.â€ There are still many â€œTerry Richardsonsâ€ in the industry, Kramer said, men whose predatory behavior the fashion world ignores. â€œWe all knew Terry Richardson was sexually abusing these girls and yet we still kept sending them on go-sees and to the bookings themselves,â€ she said. â€œIf youâ€™ve got a $20 million Revlon contract weighing in the balance ... yet you know Terry is abusing these girls, what do we do? Do we say no to Terry? No, [we] donâ€™t.â€ Moving forward, Kramer believes that if executives at top agencies spoke out about malpractice, they could truly force industrywide change. Kramer also thinks agencies need to stop accepting models under 16, but at the very least,Â she urges them to better protect young women against possible predators.Â  â€œIf I could get the owners to say to themselves, â€˜Maybe we shouldnâ€™t send 14-year-olds out on go-sees,â€™ and, â€˜Maybe we should make sure these photographers that are on the blacklist are never alone with a model,â€™ I would feel my own shame and guilt for not having done more when I was an agent [slightly dissipate],â€ she said. â€œ[Then] maybe Iâ€™d be able to let myself off the hook a little bit.â€ Do you have a story about harassment or discrimination that youâ€™d like to share? Email: angelina.chapin@huffpost.com.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Both `max_new_tokens` (=256) and `max_length`(=70) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧾 --- Summary from Fine-Tuned Model ---\n",
            "ex-model says she was groped by a photographer who allegedly raped her when she was 16 . 'i'm sick to my stomach,' she says .\n",
            "--------------------\n",
            "📊 --- METRICS ---\n",
            "• Generation Time: 2.02 s\n",
            "• Tokens per Second: 12.36\n",
            "• Word Count: 25 (from 3427 original)\n",
            "• Compression Ratio: 0.73%\n",
            "• Avg Sentence Length: 11.50 words\n",
            "• Redundancy Ratio: 20.00%\n",
            "• Readability (Flesch): 77.46\n",
            "• Gunning Fog Index: 9.82\n",
            "• SMOG Index: 10.13\n",
            "• ARI: 3.35\n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter an article to summarize (or 'quit' to exit): \u0004\n",
            "⚠️ An unexpected error occurred: \n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import time\n",
        "import textstat  # Make sure: !pip install textstat\n",
        "\n",
        "# --- 1. Load Your Fine-Tuned T5 Model ---\n",
        "try:\n",
        "    model_path = \"./my_finetuned_t_summarizer_no_ref\"\n",
        "\n",
        "    fine_tuned_summarizer = pipeline(\n",
        "        \"summarization\",\n",
        "        model=model_path,\n",
        "        tokenizer=model_path\n",
        "    )\n",
        "    print(\"\\n✅ Fine-Tuned Summarization Model Loaded\")\n",
        "    print(f\"Loaded from: {model_path}\")\n",
        "\n",
        "    # --- 2. Interactive Loop ---\n",
        "    while True:\n",
        "        article_text = input(\"\\nEnter an article to summarize (or 'quit' to exit): \")\n",
        "        if article_text.lower() == \"quit\":\n",
        "            print(\"👋 Exiting fine-tuned summarizer.\")\n",
        "            break\n",
        "        if not article_text.strip():\n",
        "            continue\n",
        "\n",
        "        prefixed_text = \"summarize: \" + article_text\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- Generate summary ---\n",
        "        result = fine_tuned_summarizer(prefixed_text, max_length=70, min_length=20, do_sample=False)\n",
        "        end_time = time.time()\n",
        "\n",
        "        summary_text = result[0][\"summary_text\"]\n",
        "\n",
        "        # --- (A) Core Metrics ---\n",
        "        generation_time = end_time - start_time\n",
        "        input_words = len(article_text.split())\n",
        "        summary_words = len(summary_text.split())\n",
        "        compression_ratio = summary_words / input_words if input_words else 0\n",
        "        tokens_per_second = summary_words / generation_time if generation_time else 0\n",
        "\n",
        "        # --- (B) Redundancy ---\n",
        "        words = summary_text.split()\n",
        "        redundancy_ratio = 1 - len(set(words)) / len(words) if words else 0\n",
        "\n",
        "        # --- (C) Sentence Structure ---\n",
        "        sentences = [s.strip() for s in summary_text.split('.') if s.strip()]\n",
        "        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0\n",
        "\n",
        "        # --- (D) Readability Metrics ---\n",
        "        flesch = textstat.flesch_reading_ease(summary_text)\n",
        "        gunning_fog = textstat.gunning_fog(summary_text)\n",
        "        smog = textstat.smog_index(summary_text)\n",
        "        ari = textstat.automated_readability_index(summary_text)\n",
        "\n",
        "        # --- (E) Output ---\n",
        "        print(\"\\n🧾 --- Summary from Fine-Tuned Model ---\")\n",
        "        print(summary_text)\n",
        "        print(\"-\" * 20)\n",
        "        print(\"📊 --- METRICS ---\")\n",
        "        print(f\"• Generation Time: {generation_time:.2f} s\")\n",
        "        print(f\"• Tokens per Second: {tokens_per_second:.2f}\")\n",
        "        print(f\"• Word Count: {summary_words} (from {input_words} original)\")\n",
        "        print(f\"• Compression Ratio: {compression_ratio:.2%}\")\n",
        "        print(f\"• Avg Sentence Length: {avg_sentence_length:.2f} words\")\n",
        "        print(f\"• Redundancy Ratio: {redundancy_ratio:.2%}\")\n",
        "        print(f\"• Readability (Flesch): {flesch:.2f}\")\n",
        "        print(f\"• Gunning Fog Index: {gunning_fog:.2f}\")\n",
        "        print(f\"• SMOG Index: {smog:.2f}\")\n",
        "        print(f\"• ARI: {ari:.2f}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "except OSError:\n",
        "    print(f\"⚠️ Error: Could not find the fine-tuned model at '{model_path}'.\")\n",
        "    print(\"Make sure the model was successfully trained and saved at that location.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws8HYzD9JAal"
      },
      "source": [
        "## ***Using the Model without Fine-tuning***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section presents the baseline performance evaluation of the generic pre-trained google-t5/t5-small model before fine-tuning. The model and tokenizer are initialized using the Hugging Face pipeline for the “summarization” task, which streamlines the process of generating summaries without additional preprocessing or configuration. To match the T5 model’s architecture, each input article is prefixed with the keyword “summarize:”, enabling the model to correctly interpret the summarization objective. The program runs in an interactive loop, allowing users to input articles and receive concise summaries in real time. The code also measures generation time, ensuring efficiency analysis, and computes additional metrics such as compression ratio and tokens per second, providing insights into the model’s processing speed and text condensation capability.\n",
        "\n",
        "After each generated summary, the script evaluates the linguistic quality and readability of the output using several intrinsic metrics. These include redundancy ratio, average sentence length, and readability indices such as Flesch Reading Ease, Gunning Fog Index, SMOG Index, and Automated Readability Index (ARI), all computed via the TextStat library. Together, these measurements assess the model’s ability to produce coherent, fluent, and accessible summaries. This baseline evaluation serves as a reference point for comparing the improvements achieved after fine-tuning, particularly in readability, conciseness, and structural consistency, thereby demonstrating the effectiveness of model optimization for news headline generation and summarization tasks."
      ],
      "metadata": {
        "id": "M1yU7rAVz4zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho11LgGT_D62",
        "outputId": "94c8ac0c-08d5-4b68-9446-7821bc0e9d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Generic Pre-trained Summarization Model Loaded (google-t5/t5-small)\n",
            "\n",
            "Enter an article to summarize (or 'quit' to exit): MANILA – The Philippine National Police (PNP) on Friday said it is preparing a comprehensive security plan to secure the country's hosting of the 2026 Association of Southeast Asian Nations (ASEAN) Summit and Related Summits.  PNP acting chief Lt. Gen. Jose Melencio Nartatez, Jr., said this was in line with the directive of President Ferdinand R. Marcos, Jr. to uphold the national commitment to hosting regional and global engagements by ensuring the highest level of safety and security for all delegates and participants.  “We are already preparing as early as now. The PNP will be on alert as meetings for our hosting have commenced. We are updating our security playbook to ensure it can address any kind of eventuality, from traffic management to VIP protection,” said Nartatez in a statement.  The country’s top police official emphasized that the core of the preparation is a meticulous review and update of all security protocols to align with modern threats and the unique atmosphere of the event.   This proactive effort involves high-level coordination with partner agencies to ensure an orderly, safe, and successful hosting of the international event.  He stressed the police force’s commitment to ensuring the smooth conduct of activities, prioritizing the safety of both the Philippine delegation and foreign visitors, particularly the heads of state.  The Acting PNP chief noted that the security strategy will be customized to support President Marcos’ vision of a “chill and hospitable” ASEAN hosting.   “Global leaders and VIPs will be part of this huge event so we want to ensure the safety and security of not just our kababayans (countrymen) but also our visitors. Nakikipag coordinate at pulong na rin tayo sa ibang mga ahensya para sa mga ipapatupad na security measures para rito (We are also coordinating and meeting with other agencies for the security measures to be implemented for this.),” Nartatez said.   He stressed that security measures must be robust yet discreet, allowing the Philippines’ renowned warmth and hospitality to shine through. (PNA)\n",
            "\n",
            "🧾 --- Generated Summary ---\n",
            "the security plan will be customized to support president Marcos' vision of a \"chill and hospitable\" ASEAN hosting . the security strategy must be robust yet discreet, allowing the Philippines’ renowned warmth and hospitality to shine through .\n",
            "--------------------\n",
            "📊 --- METRICS ---\n",
            "• Generation Time: 0.89 s\n",
            "• Tokens per Second: 42.91\n",
            "• Word Count: 38 (from 329 original)\n",
            "• Compression Ratio: 11.55%\n",
            "• Avg Sentence Length: 18.00 words\n",
            "• Redundancy Ratio: 18.42%\n",
            "• Readability (Flesch): 28.77\n",
            "• Gunning Fog Index: 18.31\n",
            "• SMOG Index: 15.90\n",
            "• ARI: 13.23\n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter an article to summarize (or 'quit' to exit): quit\n",
            "👋 Exiting generic summarizer.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import time\n",
        "import textstat\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "try:\n",
        "    summarizer = pipeline(\"summarization\", model=\"google-t5/t5-small\", tokenizer=\"google-t5/t5-small\")\n",
        "    print(\"\\n✅ Generic Pre-trained Summarization Model Loaded (google-t5/t5-small)\")\n",
        "\n",
        "    while True:\n",
        "        article_text = input(\"\\nEnter an article to summarize (or 'quit' to exit): \")\n",
        "        if article_text.lower() == \"quit\":\n",
        "            print(\"👋 Exiting generic summarizer.\")\n",
        "            break\n",
        "        if not article_text.strip():\n",
        "            continue\n",
        "\n",
        "        prefixed = \"summarize: \" + article_text\n",
        "        start_time = time.time()\n",
        "\n",
        "        result = summarizer(prefixed, max_length=50, min_length=5, do_sample=False)\n",
        "        end_time = time.time()\n",
        "\n",
        "        summary_text = result[0][\"summary_text\"]\n",
        "\n",
        "        # --- Metrics ---\n",
        "        generation_time = end_time - start_time\n",
        "        input_words = len(article_text.split())\n",
        "        summary_words = len(summary_text.split())\n",
        "        compression_ratio = summary_words / input_words if input_words else 0\n",
        "        tokens_per_second = summary_words / generation_time if generation_time else 0\n",
        "\n",
        "        words = summary_text.split()\n",
        "        redundancy_ratio = 1 - len(set(words)) / len(words) if words else 0\n",
        "\n",
        "        sentences = [s.strip() for s in summary_text.split('.') if s.strip()]\n",
        "        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0\n",
        "\n",
        "        # --- Readability ---\n",
        "        flesch = textstat.flesch_reading_ease(summary_text)\n",
        "        gunning_fog = textstat.gunning_fog(summary_text)\n",
        "        smog = textstat.smog_index(summary_text)\n",
        "        ari = textstat.automated_readability_index(summary_text)\n",
        "\n",
        "        # --- Output ---\n",
        "        print(\"\\n🧾 --- Generated Summary ---\")\n",
        "        print(summary_text)\n",
        "        print(\"-\" * 20)\n",
        "        print(\"📊 --- METRICS ---\")\n",
        "        print(f\"• Generation Time: {generation_time:.2f} s\")\n",
        "        print(f\"• Tokens per Second: {tokens_per_second:.2f}\")\n",
        "        print(f\"• Word Count: {summary_words} (from {input_words} original)\")\n",
        "        print(f\"• Compression Ratio: {compression_ratio:.2%}\")\n",
        "        print(f\"• Avg Sentence Length: {avg_sentence_length:.2f} words\")\n",
        "        print(f\"• Redundancy Ratio: {redundancy_ratio:.2%}\")\n",
        "        print(f\"• Readability (Flesch): {flesch:.2f}\")\n",
        "        print(f\"• Gunning Fog Index: {gunning_fog:.2f}\")\n",
        "        print(f\"• SMOG Index: {smog:.2f}\")\n",
        "        print(f\"• ARI: {ari:.2f}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08d199b1acdb422abd16106adeb969c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5717ad74dc8c4f778aecd357bdbdb4e1",
            "max": 1375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cbc48c8e63f42d6bfebcaf97b2bdc61",
            "value": 1375
          }
        },
        "12b22da8f1f64d2982594d5a85f14926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5ab3db47254c6cb8db282c7e18989c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2616897baeb140e0907613d53ec752c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa2a0f336bc475c91b3e0db36ba29b8",
            "max": 710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9684c048f8104f98bcfd332c8f8a773d",
            "value": 710
          }
        },
        "2cbc48c8e63f42d6bfebcaf97b2bdc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32c34aa74fdb460da8ef023424e74687": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "358a7620c7c04202be048363abe7062b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da7e6b3dc2a41d6be11342d87d90006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42c05f095e674554aec38077b1cd1645",
              "IPY_MODEL_2616897baeb140e0907613d53ec752c6",
              "IPY_MODEL_80c41c2a9ed5447ea2d069a90da5c783"
            ],
            "layout": "IPY_MODEL_63e3750b4dd34baab57b1c4bd987f8b5"
          }
        },
        "3fd9e6ff668e4926baf065c911b1af42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c05f095e674554aec38077b1cd1645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd9e6ff668e4926baf065c911b1af42",
            "placeholder": "​",
            "style": "IPY_MODEL_c29403752b2945d8950b4ecbe6b6437f",
            "value": "Map: 100%"
          }
        },
        "498c80767dbe4a65a5627826defa52bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c9f83e0999494ca8ef3572ed7ebe03",
            "placeholder": "​",
            "style": "IPY_MODEL_e80ac48f55cc46bcb436a4f8157b0f8c",
            "value": "Filter: 100%"
          }
        },
        "5717ad74dc8c4f778aecd357bdbdb4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3250f69e52412b8d8b50cb97f92432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601c4340aa564b399705793aa26580cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e3750b4dd34baab57b1c4bd987f8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70834a49b8fb49a2a7d823fddd0fd48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dabce246638b4be9a6de5faf6544b467",
              "IPY_MODEL_a1fa520c39ef481db10aca6b8d23344e",
              "IPY_MODEL_a6273132062f4f54aaa20be847c9b576"
            ],
            "layout": "IPY_MODEL_cc36413f96e8485e88b928874fa0d6c1"
          }
        },
        "734297a7e26d4797baca06a2850b625b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa2a0f336bc475c91b3e0db36ba29b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfa75101ed34b669c61f4537bf8e19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e07f49906b4a09af67b1631ce7abc1",
            "placeholder": "​",
            "style": "IPY_MODEL_d0dff8f712934fa7970cde3dad3c8a77",
            "value": " 5497/5497 [00:00&lt;00:00, 12478.86 examples/s]"
          }
        },
        "80c41c2a9ed5447ea2d069a90da5c783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90cc5df54a2c4b3e8f749796a6a0c281",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3250f69e52412b8d8b50cb97f92432",
            "value": " 710/710 [00:01&lt;00:00, 640.99 examples/s]"
          }
        },
        "8200259801d94befbc47944ad58b8890": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8865670bc81b487dac831a3f6c4926d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9084a52f55ed4ff4b63bc9c257de1806": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90cc5df54a2c4b3e8f749796a6a0c281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f2f292ed8347d8bd15ce1bca5a2ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac65e29d57af4b8085b27d2e7aecdba8",
            "placeholder": "​",
            "style": "IPY_MODEL_32c34aa74fdb460da8ef023424e74687",
            "value": "Filter: 100%"
          }
        },
        "94137c4a0a25440c9c95e027e43760b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9084a52f55ed4ff4b63bc9c257de1806",
            "max": 5497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a200d03fda424f45869fd0ebcfa103b5",
            "value": 5497
          }
        },
        "9684c048f8104f98bcfd332c8f8a773d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1fa520c39ef481db10aca6b8d23344e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_358a7620c7c04202be048363abe7062b",
            "max": 2817,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a74edb05b79a46b5a405de769488386a",
            "value": 2817
          }
        },
        "a200d03fda424f45869fd0ebcfa103b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6273132062f4f54aaa20be847c9b576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601c4340aa564b399705793aa26580cb",
            "placeholder": "​",
            "style": "IPY_MODEL_dec2636300e744cf83704ebd0dcf25d2",
            "value": " 2817/2817 [00:04&lt;00:00, 643.43 examples/s]"
          }
        },
        "a74edb05b79a46b5a405de769488386a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac65e29d57af4b8085b27d2e7aecdba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13e2bfa3d624cc498bd2d8c300ff642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91f2f292ed8347d8bd15ce1bca5a2ffa",
              "IPY_MODEL_94137c4a0a25440c9c95e027e43760b4",
              "IPY_MODEL_7bfa75101ed34b669c61f4537bf8e19c"
            ],
            "layout": "IPY_MODEL_12b22da8f1f64d2982594d5a85f14926"
          }
        },
        "b5a6071a13414040836600b606a0839b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29403752b2945d8950b4ecbe6b6437f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e07f49906b4a09af67b1631ce7abc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc36413f96e8485e88b928874fa0d6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dff8f712934fa7970cde3dad3c8a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d312e3bfa43d47ada098a2ea49e6fb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5ab3db47254c6cb8db282c7e18989c",
            "placeholder": "​",
            "style": "IPY_MODEL_8865670bc81b487dac831a3f6c4926d0",
            "value": " 1375/1375 [00:00&lt;00:00, 9858.23 examples/s]"
          }
        },
        "dabce246638b4be9a6de5faf6544b467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a6071a13414040836600b606a0839b",
            "placeholder": "​",
            "style": "IPY_MODEL_8200259801d94befbc47944ad58b8890",
            "value": "Map: 100%"
          }
        },
        "dec2636300e744cf83704ebd0dcf25d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e397574e8bd149f6bc46583b7ae0f42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_498c80767dbe4a65a5627826defa52bb",
              "IPY_MODEL_08d199b1acdb422abd16106adeb969c2",
              "IPY_MODEL_d312e3bfa43d47ada098a2ea49e6fb54"
            ],
            "layout": "IPY_MODEL_734297a7e26d4797baca06a2850b625b"
          }
        },
        "e6c9f83e0999494ca8ef3572ed7ebe03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80ac48f55cc46bcb436a4f8157b0f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}